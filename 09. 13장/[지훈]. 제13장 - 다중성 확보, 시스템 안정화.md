
# 13. 다중성 확보, 시스템 안정화

다중화를 위해서 가장 중요시하는 것은 **SPOF(Single Point of Failure)** 즉, 단일 장애점을 제거하는 것이다.
( 한 곳에 장애가 나면 시스템이 멈춰버리는 부분을 가능한 한 없앰으로써 가동률을 높이도록 함 )

이번 장에서는 거의 100% 가동률을 살현하는 다중성 확보의 원리를 살펴본다.

# 다중성 확보

## 다중성 확보 - AP 서버

AP 서버에서는 확장성을 생각하는 방식과 마찬가지로 서버 여러 대를 늘어놓는 것이 기본이 된다.

- 서버를 늘어놓을 때 중요한 것은 
**1대나 2대 정도 정지하더라도 충분히 처리할 수 있도록 처리 능력을 확보**해두는 것이다.

서버는 다양한 요인으로 멈춘다. 이에 대한 대응으로

![image.png](attachment:96031151-fe75-43ed-aea8-f405971f89da:image.png)

- 로드밸런서로 `페일오버(failover, 장애극복)`, `페일백(failback, 정상 복귀)`하여 
****고장 난 서버를 자동적으로 분리하고, 서버가 복구되면 원 상태로 복귀시키는 작업을 수행하고 있다.
    - `페일오버(failover, 장애극복)`  : 고장난 서버를 자동으로 분리하는 것
    - `페일백(failback, 정상 복귀)`  : 정상이 되면 다시 복귀시키는 처리
- 로드밸런서는 서버에 대해 주기적으로 헬스체크를 하고 있으며, 이는 다중화에서 가장 기본적인 부분이다.

## 다중성 확보 - DB 서버

DB 서버도 마찬가지로 서버를 여러 대 나열해서 1, 2대 정지하더라도
충분한 처리능력이 있도록 해주는 것이 중요하다.

여기서 마스터 다중화도 수행하고 있는데,

마스터 다중화는 어려운 편이라서, 하테나는 마스터 다중화를 위해서 `멀티 마스터`라는 방법을 사용한다.

### 멀티 마스터

멀티 마스터는 쌍방 레플리케이션.
즉, 서로가 서로의 슬레이브가 되는 상태로 해두고 한쪽에 쓰기 작업을 하면 다른 한쪽으로 전달하고 반대쪽에 쓰더라도 다른 쪽으로 전달하는 양방향 레플리케이션 방법이다.

- 다만 MySQL은 실제로 한쪽에 쓰기작업을 하면 반대쪽으로 전달되는 흐름이기 때문에 약간의 지연이 있다.
- 이 타이밍에 한쪽이 다운되어 분리되면 양쪽에 동기화가 맞지 않는 상황이 발생한다.

엔터프라이즈에서는 이 부분에 대한 대책으로 레플리케이션을 동기적으로 처리함으로써 대처한다.
(슬레이브까지 쓰였다는 것을 확인한 다음에 클라이언트에 결과를 반환)

- 이 경우 동기는 확실하게 담보되지만 성능면에서 큰 손실이 발생한다.
- 웹 서비스에서는 동기가 맞지 않는 리스크에 대해서 어느 정도 받아들임으로써 성능을 중시하는 경우가 많다.

### 페일오버 동작방식

- 마스터 간에 VRRP(Virtual Router Redundancy Protocol)이라는 프로토콜로 서로를 감시한다.

  → VRRP에 의해 한쪽이 분리된 것을 알게 되면 자신이 Active 마스터로 승격한다.


구체적으로 살펴보자면,

![image.png](attachment:67d40579-2ec3-4962-8aa6-1cc9df81df0b:image.png)

- 서버는 기본적으로 2대 있으며 Active/Standby 구성을 하고 있다.
    - 기본적으로 항상 Active 쪽만 쓰기 작업을 하는 구성
- Active 서버가 다운되면 Standby였던 쪽이 Active로 승격해서 새로운 마스터가 되고,
  다운된 서버는 수작업으로 복구시켜서 다시 Standby로 되돌리던가 다시 원래의 구성으로 되돌린다.
- 외부에서 어느 쪽 서버가 Active인지 판단하기 위해 Virtual IP를 사용한다.
    - ex)
        - 실제 두 서버가 0.1(Active), 0.2(Standby)라는 주소를 가지고 있다면
          새롭게 0.3이라는 가상 주소를 Active 쪽에 할당한다
        - Active 쪽에는 0.1, 0.3 두 주소로 엑세스 할 수 있다.
        - AP서버는 0.3 주소를 사용하도록 정해져 있고
          0.1, 0.3(Active)서버에 장애가 나서 FailOver 될 경우
          0.2 서버를 Active로 바꾸고 0.3 가상주소를 다시 부여한다.

  → 이런 식으로 구성함으로써 AP 서버 입장에서는 마스터 전환이 은폐되는 효과를 얻을 수 있다.


# 시스템 안정화

## 시스템 안정화를 위한 상반관계

시스템을 안정화시키기 위해 상반되는 부분이 몇 가지 있다.

- **안정성과 자원 효율**
- **안정성과 속도**

구체적인 사례로는 **메모리나 CPU를 한계에 이를 때까지 사용하면 장애가 발생**할 수 있다.

- 메모리를 빠듯하게 튜닝한 경우

  → 메모리가 늘어났을 때,
  곧바로 스왑을 사용하기 시작해서 성능이 저하되고 서비스 장애로 이어진다.

- CPU를 한계에 다다를 정도로 사용할 경우
  → 서버 대수는 줄일 수 있겠지만
  한계에 다다른 상태에서 1대에 장애가 발생하면 전체적으로 처리능력이 부족해져서
  요청을 다 처리하지 못하고 막혀서 장애 될 수 있다.

이렇게 되지 않게 취해야 하는 대책으로

- 메모리는 7할 정도까지만 사용한다거나 CPU를 7할 정도까지만 사용하는 등 어느 정도 여유를 가질 수 있게 설계하는 것이 중요하다.
- 한계에 다다를 정도로 사용하지 않고 어느 정도 버퍼를 유지하고 버퍼가 부족해지면 새로운 서버를 추가하거나 구성을 약간 변경해서 전체적인 사용량을 줄이는 대책을 계속해감으로써 안정성을 확보할 수 있다.

## 시스템의 불안정 요인

### 기능 추가, 메모리 누수

- 애플리케이션, 서비스 레벨에서 기능을 추가하면 그 기능이 예상보다 무거워서
  전체적인 부하가 늘어나 서비스가 다운될 가능성이 있다.
- 메모리가 조금씩 누수되지만 이를 알지 못한다면
  시간이 지남에 따라 버퍼를 다 사용해서 스왑을 사용하기 시작해서 부하가 증가하는 경우도 있다.

### 지뢰

- 지뢰란?
    - 특정 url을 읽으면 응답이 오지 않아서 장애의 요인이 되는 것
- 이 지뢰를 밟으면 잘 작동되고 있던 시스템이 갑자기 무거워 지면서 다운되다보니
  지뢰를 밟은 직후 시스템이 다운되기 전에 원인을 찾지 못하면 어디에서 뭐가 지뢰가 되고 있는지 파악하기 어렵다. → 이 책에서는 지뢰가 어딘지, 뭐가 문제였는지 파악하기 위해 gdb 디버거를 사용한다고 함.
    - ❗ 요즘은 DagaDog, 키바나 같은 모니터링 툴이 잘 되있어서 이걸로 파악 가능!
- 애초에 지뢰를 만들지 않아야 하지만 그건 매우 어렵기 때문에
  밟더라도 치명적인 문제가 되지 않도록 설계하는 것이 중요하다.

### 사용자의 액세스 패턴

- 갑자기 사용자의 액세스 횟수가 급증 할 경우, 시스템 부하가 올라갈 수 있다.
- 이러한 액세스 변동도 흡수 할 수 있도록 시스템을 구성하는게 중요한데,
  캐시 서버를 사이에 추가해서 게스트 사용자의 경우는 캐시를 반환할 수 있도록 해두는 방법이 있다.

### 데이터량 증가

- 예상했던 보다 데이터량이 늘어나서 전체적인 부하의 증가로 이어져서 시스템이 불안정해지는 경우가 있다.
    - ex) 하테나에는 버튼을 클릭헤서 별표시를 다는 기능이 있었는데,
      아이들이 이걸 너무 클릭해서 데이터량이 급증해서 장애가 난 경우가 있음
- 대응: DB 설계를 변경해서 전체적인 레코드 수의 증가를 억제해 데이터량의 규모를 적정한 수준으로 줄이는 대책이 있다.
    - ex) 별 1000개를 달면 1000개의 레코드를 추가하는 방식에서,
      1000개를 추가했다는 정보를 가진 레코드를 1개만 추가하는 방식으로 변경

### 외부 연계 추가

- 외부 연계 추가란?
    - 광고 관련 웹 API나 Amazon 웹 API를 추가하는 등 외부의 새로운 웹  API를 연결하는 것을 말한다.
- 외부연계를 늘리게 되면 외부 시스템이 다운되어 있을 때 덩달아서 다운되는 형태가 되기 쉬우므로,
  외부시스템이 다운되거나 다운되지는 않더라도 부하가 높을 때에도 연계하고 있는 서비스가 영향을 받지 않도록 충분한 속도로 동작하거나 외부로부터 데이터를 가져올 수는 없지만 그 부분만 작동을 안 하고 다른 부분을 출력할 수 있도록 하는 등 외부 노이즈에 견딜 수 있는 시스템을 구현하는 것도 중요하다.

### 메모리, HDD 장애, NIC 장애

- 메모리나 HDD, 네트워크 장애는 일상적으로 발생한다.
- 하드웨어의 능력이 저하되더라도 문제가 되지 않도록 해두는 것이 중요하다.
- 예를 들어 로드밸런서에서 적절한 항목에 대해 헬스체크를 해서 하드웨어 장애로 이상이 생겼을 때 바로 문제가 발생한 서버로 요청이 전송되지 않도록 할 수 있다.

# 시스템 안정화 대책
안정화를 위한 사고방식에 대해 지금까지 언급했다.
실제 대책을 취하고 있는 방식은 대표적으로 아래와 같다.

### 적절한 버퍼 유지를 위해 한계의 7할까지 운용한다.

시스템 수용 능력의 70%를 상한선으로 해서 이를 넘어서면 서버를 추가하거나 메모리를 늘리는 등
임계치를 설정하는 방식을 취하고 있다.

### 불안정 요인의 제거

불안정 요인을 제거하는 데에는 SQL 부하 대책, 메모리 누수 줄이기, 비정상 동작 시 자율제어 등을 예로 들 수 있다.

**SQL 부하**

- 부하가 높아질 듯한 SQL을 발행하지 않도록 하는 것은 시스템을 안정화시키기 위해 매우 중요하다.
- 엔지니어는 자신의 서비스가 어떤 SQL을 발행하는지 파악해두고,
  부하가 높아질 만한 SQL을 발행할 경우 해당 용도를 위해 격리시킨 DB를 준비해서
  거기로 SQL을 날리도록 한다.

**메모리 누수 줄이기**

메모리 누수를 줄이는건 기본이므로
엔지니어가 매일 수행하고 있다.

### 이상 동작 시의 자율제어

이상 동작 시의 자율제어 대책으로 아래 세가지를 수행하고 있다.

**자동 Dos 판정**

- 1시간에 특정 IP주소로부터 다수의 요청이 오면,
  당분간 403을 반환해서 액세스를 자율적으로 차단함으로써 비정상 액세스에 대처한다.

**자동 재시작**

- 어느 정도 리소스를 지나치게 사용했다고 판단했다면 웹 서버를 재시작한다.
- 또한 가상화되어 있는 호스트에서는 가상화되어 있는 OS별로 재시작을 한다.

**자동 쿼리 제거**

- DB서버에 어떤 쿼리가 실행되는지 일적 시간 주기로 파악하고
  소요시간이 긴 SQL을 강제적으로 KILL한다.